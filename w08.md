---
permalink: /W08/
---
[HOME](../)<br>
[<< PREVIOUS |](../W07/)<br>

# Top 10 List of Week 08

1. **[What is CPU Scheduling?](https://www.guru99.com/cpu-scheduling-algorithms.html)** <br>
**CPU Scheduling** is a process of determining which process will own CPU for execution while another process is on hold. The main task of CPU scheduling is to make sure that whenever the CPU remains idle, the OS at least select one of the processes available in the ready queue for execution. The selection process will be carried out by the CPU scheduler. It selects one of the processes in memory that are ready for execution. <br>
* * *

2. **[Preemptive vs Non-Preemptive Scheduling](https://www.geeksforgeeks.org/preemptive-and-non-preemptive-scheduling/)** <br>
In **Preemptive Scheduling**, the tasks are mostly assigned with their priorities. In **Non-preemptive Scheduling**, the CPU has been allocated to a specific process. To determine if scheduling is preemptive or non-preemptive, consider these four parameters: 1) **A process switches from the running to the waiting state**; 2) **Specific process switches from the running state to the ready state**; 3) **Specific process switches from the waiting state to the ready state**; 4) **Process finished its execution and terminated**. If only conditions 1 and 4 apply, the scheduling is called non-preemptive. All other scheduling are preemptive.<br>
* * *

3. **[Scheduling Algorithms](https://www.javatpoint.com/os-scheduling-algorithms)** <br>
There are various algorithms which are used by the Operating System to schedule the processes on the processor in an efficient way. The purpose of a scheduling algorithm is to get: Maximum CPU utilization, Fare allocation of CPU, Maximum throughput, Minimum turnaround time, Minimum waiting time, and Minimum response time. There are mainly six types of process scheduling algorithms: **First Come First Serve (FCFS)**, **Shortest-Job-First (SJF) Scheduling**, **Shortest Remaining Time**, **Priority Scheduling**, **Round Robin Scheduling**, and **Multilevel Queue Scheduling**. <br>
* * *

4. **[CPU & I/O Burst Cycle](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/6_CPU_Scheduling.html)** <br>
**CPU/IO burst cycle**: Characterizes process execution, which alternates between CPU and I/O activity. CPU times are usually shorter than the time of I/O. Almost all programs have some alternating cycle of CPU number crunching and waiting for I/O of some kind. In a simple system running a single process, the time spent waiting for I/O is wasted, and those CPU cycles are lost forever. A scheduling system allows one process to use the CPU while another is waiting for I/O, thereby making full use of otherwise lost CPU cycles. Almost all processes alternate between two states in a continuing cycle: A **CPU burst** of performing calculations, and an **I/O burst**, waiting for data transfer in or out of the system. <br>
* * *

5. **[What is Dispatcher?]()** <br>
A **Dispatcher** is a module that provides control of the CPU to the process. The Dispatcher should be fast so that it can run on every context switch. Dispatch latency is the amount of time needed by the CPU scheduler to stop one process and start another. Functions performed by Dispatcher are: Context Switching, Switching to user mode, and Moving to the correct location in the newly loaded program. <br>
* * *

6. **[What is Thread Scheduling?](https://www.geeksforgeeks.org/thread-scheduling/)** <br>
The basic difference between semaphore and mutex is that semaphore is a signalling mechanism i.e. processes perform wait() and signal() operation to indicate whether they are acquiring or releasing the resource, while Mutex is locking mechanism, the process has to acquire the lock on mutex object if it wants to acquire the resource. Semaphore is a better option in case there are multiple instances of resources available. In the case of single shared resource mutex is a better choice. <br>
* * *

7. **[User-level vs Kernel-level Threads](https://www.tutorialspoint.com/user-level-threads-and-kernel-level-threads#:~:text=Kernel%2Dlevel%20threads%20are%20handled,slower%20than%20user%2Dlevel%20threads.)** <br>
The two main types of threads are **User-level threads** and **Kernel-level threads**. **User-level threads** are implemented by users and the kernel is not aware of the existence of these threads. It handles them as if they were single-threaded processes. User-level threads are small and much faster than kernel level threads. **Kernel-level threads** are handled by the operating system directly and the thread management is done by the kernel. The context information for the process as well as the process threads is all managed by the kernel. Because of this, kernel-level threads are slower than user-level threads. <br>
* * *

8. **[Multiprocessor Scheduling in Operating System](https://www.includehelp.com/operating-systems/multiprocessor-scheduling-in-operating-system.aspx#:~:text=In%20the%20multiprocessor%20scheduling%2C%20there%20are%20many%20processors%20and%20they,is%20a%20tightly%20coupled%20system.)** <br>
In the multiprocessor scheduling, there are multiple CPU’s which share the load so that various process run simultaneously. In general, the multiprocessor scheduling is complex as compared to single processor scheduling. In the multiprocessor scheduling, there are many processors and they are identical and we can run any process at any time. The multiple CPU’s in the system are in the close communication which shares a common bus, memory and other peripheral devices. So we can say that the system is a tightly coupled system. These systems are used when we want to process a bulk amount of data. These systems are mainly used in satellite, weather forecasting etc. <br>
* * *

9. **[Banker's Algorithm in Operating System](https://www.guru99.com/bankers-algorithm-in-operating-system.html)** <br>
Banker's algorithm is used majorly in the banking system to avoid deadlock. It helps you to identify whether a loan will be given or not. Notations used in banker's algorithms are 1) **Available** 2) **Max** 3) **Allocation** 4) **Need**. Resource request algorithm enables you to represent the system behavior when a specific process makes a resource request. Banker's algorithm keeps many resources that satisfy the requirement of at least one client. The biggest drawback of banker's algorithm this that it does not allow the process to change its Maximum need while processing. <br>
* * *

10. **[Message Passing Model of Process Communication](https://www.tutorialspoint.com/message-passing-model-of-process-communication#:~:text=Message%20passing%20model%20allows%20multiple,used%20by%20most%20operating%20systems.)** <br>
Process communication is the mechanism provided by the operating system that allows processes to communicate with each other. This communication could involve a process letting another process know that some event has occurred or transferring of data from one process to another. One of the models of process communication is the message passing model. Message passing model allows multiple processes to read and write data to the message queue without being connected to each other. Messages are stored on the queue until their recipient retrieves them. Message queues are quite useful for interprocess communication and are used by most operating systems. <br>
* * *
